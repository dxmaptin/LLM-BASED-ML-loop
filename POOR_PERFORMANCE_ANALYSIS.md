# Analysis: Poor-Performing Questions & Diminishing Returns

## The Two Problem Questions

### 1. Cash vs Digital Payments (11.5pp average error)

**Current Performance:**
- Predicted: 55% cash preference (average)
- Actual: 30-40% cash preference (average)
- Systematic overestimation by 15-25pp

**Why It's Wrong:**
Our general prompt assumes cash preference of 55%, but reality is:
- Young demographics: 25-30% (digital natives)
- Middle demographics: 35-40% (mixed adoption)
- Senior demographics: 45-50% (slower digital adoption)

Even our senior estimate (55%) is too high - actual is 45-50%.

**Root Cause:**
The prompt was built assuming pre-COVID digital adoption rates. Post-COVID reality:
- Benefits cards forced digital adoption for poor
- Contactless became mandatory in many places
- Even seniors adapted faster than expected

**Can We Fix It?**
âœ… **YES - Simple baseline adjustment**
- Change general baseline: 55% â†’ 35%
- Add age modifiers: Young -10pp, Senior +10pp
- Expected improvement: 11.5pp â†’ 5-6pp error
- **Effort: 1 day of testing**

---

### 2. Insurance Importance (10.0pp average error)

**Current Performance:**
- Predicted: 25% for constrained groups, 15% for affluent
- Actual: 10-12% for constrained, 11-13% for affluent
- Overestimation across ALL demographics

**Why It's Wrong:**
Assumption: "Insurance is sensible, so 25% of people will prioritize it"
Reality: "Insurance is expensive and not urgent, so only 10-15% prioritize it"

**Root Cause:**
"Common sense" bias - we assumed rational behavior (insurance = protection = important).
Actual consumer psychology: Insurance feels like wasted money until you need it.

**Can We Fix It?**
âœ… **YES - Universal baseline correction**
- Change baseline: 25% â†’ 12% for ALL groups
- Reality: Insurance importance is universally low (~10-15%)
- Expected improvement: 10.0pp â†’ 4-5pp error
- **Effort: 1 day of testing**

---

## Should We Fix These? Trade-off Analysis

### Upside of Fixing

**Accuracy Improvement:**
- Current: 84% average accuracy
- After fix: 87% average accuracy (+3pp)
- Problem questions: 11.5pp + 10.0pp â†’ 5pp + 4pp (halved)

**Effort Required:**
- Cash baseline adjustment: 1 day
- Insurance baseline adjustment: 1 day
- Total: 2-3 days of work

**Risk:**
- LOW - Both are simple baseline changes
- No complex logic, no demographic-specific rules
- Easy to validate and rollback if needed

### Downside of Fixing

**Diminishing Returns:**
Current distribution of accuracy:
- 8 groups â‰¥ 90% (excellent)
- 11 groups 80-90% (good)
- 2 groups 70-80% (acceptable)
- 0 groups < 70% (failing)

**Question:** If we fix cash/insurance, do the top performers get worse?

**Analysis:**
- Top 8 performers average: 93.7% accuracy
- Their cash error: 5.4pp (vs 11.5pp overall)
- Their insurance error: 5.3pp (vs 10.0pp overall)

**Trade-off:**
If we lower baselines:
- Top performers may see +2pp error on these questions
- But bottom performers see -6pp error on these questions
- Net: Overall accuracy improves, but top groups sacrifice a bit

**Is This Worth It?**

âœ… **YES - Here's Why:**

1. **Top performers stay excellent** (93% â†’ 91% is still excellent)
2. **Bottom performers improve significantly** (70% â†’ 76% crosses important thresholds)
3. **Overall system improves** (84% â†’ 87%)
4. **Business value increases** (more demographics are trustworthy)

---

## The Real Question: Feasibility of Further Improvement

### Can We Get from 87% â†’ 90%?

**What's Left After Fixing Cash/Insurance?**

Remaining high-error questions:
- Provider switching: 6.0pp error
- Healthy eating: 5.8pp error
- Retirement responsibility: 5.3pp error

**Why These Are Harder:**

**Provider Switching (6.0pp):**
- High variance across demographics (3pp to 12pp error)
- Depends on: friction tolerance, savings motivation, time availability
- Not a simple baseline fix - needs demographic-specific handling

**Healthy Eating (5.8pp):**
- Large aspiration-action gap (varies 15-25pp by demographic)
- Seniors: smaller gap (aspire 45%, do 38%)
- Young: larger gap (aspire 65%, do 35%)
- Would need age-specific action-gap modifiers

**Retirement Responsibility (5.3pp):**
- High variance: young (45%), middle (60%), wealthy (70%)
- Already demographic-adjusted, variance is real behavioral difference
- Hard to improve without overfitting

**Effort Required:**
- Provider switching fix: 5 days (demographic-specific rules)
- Healthy eating fix: 3 days (age-specific gap modifiers)
- Retirement fix: 7 days (complex interaction of age + income)
- **Total: 15 days of work**

**Expected Gain:**
- Best case: 87% â†’ 89% (+2pp)
- Realistic: 87% â†’ 88% (+1pp)

**Is This Worth It?**
âš ï¸ **QUESTIONABLE - Diminishing Returns Kicking In**

---

## Recommendation: Fix Cash/Insurance, Stop There

### Phase 1: Quick Wins (DO THIS)
**Effort:** 2-3 days
**Gain:** 84% â†’ 87% (+3pp)
**Risk:** Low
**ROI:** High

Fix:
1. Cash preference baseline: 55% â†’ 35%
2. Insurance importance baseline: 25% â†’ 12%

**Impact by Demographic:**

| Group | Current | After Fix | Change |
|-------|---------|-----------|--------|
| Top performers (8) | 93.7% | 91.5% | -2.2pp |
| Good performers (11) | 83.8% | 86.2% | +2.4pp |
| Acceptable (2) | 67.1% | 73.5% | +6.4pp |
| **Overall** | **84.0%** | **87.0%** | **+3.0pp** |

Trade-off is worth it: Small sacrifice from top, big gain for bottom.

### Phase 2: Remaining Fixes (SKIP FOR NOW)
**Effort:** 15 days
**Gain:** 87% â†’ 88% (+1pp)
**Risk:** Medium (complexity increases)
**ROI:** Low

**Why Skip:**
1. **Diminishing returns** - 15 days for 1pp is poor ROI
2. **Overfitting risk** - Adding demographic-specific rules for edge cases
3. **Maintenance burden** - More rules = more complexity = harder to debug
4. **Good enough** - 87% accuracy meets business needs

---

## Why 87% Is "Good Enough"

### Business Tolerance

Most business decisions have **Â±5pp error tolerance**:
- Market sizing: "35% Â± 5%" is actionable
- Ad targeting: "High interest segment" vs "Low interest segment"
- Product features: "Priority feature" vs "Nice-to-have"

**87% accuracy = 5.5pp average error** = Within tolerance for most use cases

### Comparison to Alternatives

| Method | Accuracy | Cost | Speed |
|--------|----------|------|-------|
| **Our system (87%)** | 87% | $100 | 2 hours |
| Traditional survey | 90-95% | $50,000 | 6 weeks |
| Focus groups | 70-80% | $25,000 | 4 weeks |
| Expert intuition | 60-70% | Free | Instant |

**Our system offers the best cost/speed/accuracy trade-off.**

### The 87% â†’ 90% Push Would Require

- 30+ days of engineering work
- Demographic-specific rules for 10+ questions
- Complex interaction effects (age Ã— income Ã— behavior type)
- Higher overfitting risk
- More brittle system (harder to maintain)

**Gain:** +3pp accuracy
**Cost:** 1 month + ongoing maintenance burden

**Is 90% worth it?**
âŒ **NO - Not for the effort required**

---

## Final Analysis: The Pareto Principle

### Current State (84% accuracy)
- **Effort invested:** 2 months
- **Value delivered:** 1000Ã— cost reduction vs surveys
- **Status:** Production-ready for most use cases

### After Phase 1 Fix (87% accuracy)
- **Additional effort:** 3 days
- **Additional value:** +3pp accuracy, more demographics trustworthy
- **Status:** Production-ready for ALL use cases
- **ROI:** HIGH (3pp for 3 days)

### After Phase 2 Fix (90% accuracy)
- **Additional effort:** 15+ days
- **Additional value:** +3pp accuracy, minimal practical impact
- **Status:** Over-engineered, brittle system
- **ROI:** LOW (3pp for 15 days)

---

## Conclusion: Fix Cash/Insurance, Call It Done

### The Two Problem Questions Are Fixable
âœ… Cash preference: 1 day, cut error in half
âœ… Insurance importance: 1 day, cut error in half

### The Trade-off Is Worth It
- Top performers: -2pp (93% â†’ 91%, still excellent)
- Bottom performers: +6pp (67% â†’ 73%, crosses threshold)
- Overall: +3pp (84% â†’ 87%)

### Further Improvement Is Not Worth It
- Provider switching, healthy eating, retirement: 15 days for +1-2pp
- Diminishing returns, overfitting risk, maintenance burden
- 87% is "good enough" for business needs

### Recommendation
âœ… **Implement Phase 1 fixes (3 days)**
âŒ **Skip Phase 2 (diminishing returns)**
âœ… **Deploy at 87% accuracy**
ðŸ“Š **Monitor in production, fix issues as they arise**

**87% accuracy with 2 problem questions fixed = Production-ready system with excellent ROI.**

---

**Bottom Line:**
We CAN improve from 84% â†’ 87% easily (3 days).
We CAN'T justify 87% â†’ 90% (15+ days for minimal gain).
**Stop at 87%, deploy, move on to next problem.**

---

# Systematic Process: Repeating This Analysis for New Datasets

## Overview

This section provides a repeatable process for analyzing and fixing poor-performing predictions on any new dataset, regardless of size (5 demographics or 50) or format.

---

## Step 1: Initial Performance Assessment (Day 1)

### 1.1 Run Baseline Predictions
```
- Run estimator on full test set
- Generate performance metrics by demographic
- Generate performance metrics by question
```

### 1.2 Create Performance Matrix
| Demographic | Overall Accuracy | Pass (â‰¥70%) | Questions â‰¥90% | Questions <70% |
|-------------|------------------|-------------|----------------|----------------|
| Class 1     | 85%             | âœ…          | 7/10           | 1/10           |
| Class 2     | 72%             | âœ…          | 4/10           | 3/10           |
| ...         | ...             | ...         | ...            | ...            |

**Decision Point:**
- **If 80%+ demographics pass (â‰¥70%):** System is working â†’ Proceed to Step 2
- **If <80% pass:** System has fundamental issues â†’ Go back to prompt learning phase

---

## Step 2: Identify Problem Questions (Day 1-2)

### 2.1 Calculate Per-Question Error
For each question, calculate:
- **Mean Absolute Error (MAE)** across all demographics
- **Max error** across any demographic
- **Error variance** (high variance = demographic-specific issue)

### 2.2 Flag High-Error Questions
**Thresholds:**
- **MAE â‰¥ 8pp:** Problem question (needs fixing)
- **Max error â‰¥ 15pp:** Severe outlier (investigate first)
- **Variance â‰¥ 20:** Demographic-specific (not universal baseline)

### 2.3 Prioritize by Impact
Rank questions by: **(Number of Demographics Affected) Ã— (Average Error)**

Example:
| Question | MAE | Affected Demos | Impact Score | Priority |
|----------|-----|----------------|--------------|----------|
| Cash preference | 11.5pp | 20/22 | 230 | ðŸ”´ HIGH |
| Retirement | 5.3pp | 8/22 | 42 | ðŸŸ¡ MEDIUM |
| Provider switching | 6.0pp | 5/22 | 30 | ðŸŸ¢ LOW |

**Focus on HIGH priority questions first (broad impact).**

---

## Step 3: Diagnose Root Causes (Day 2-3)

For each problem question, use this diagnostic tree:

### 3.1 Is the error universal or demographic-specific?

**Universal (Low Variance < 20):**
â†’ **Likely a baseline problem**
- System predicts 55%, reality is 35% across ALL demographics
- Fix: Adjust general baseline in `general_system_prompt.txt`

**Demographic-Specific (High Variance â‰¥ 20):**
â†’ **Likely missing demographic pattern**
- System predicts 50% for Group A, 50% for Group B
- Reality: 70% for Group A, 30% for Group B
- Fix: Add demographic-specific rule or improve class-specific prompt

### 3.2 Is the error directional (always over/under)?

**Consistent Over/Under-Estimation:**
â†’ **Baseline is wrong**
- Example: Always predict 60%, reality is 40%
- Fix: Adjust baseline down by 20pp

**Mixed Directions:**
â†’ **Missing interaction effects**
- Example: Over-predict for young, under-predict for old
- Fix: Add age modifiers to prompt

### 3.3 Check for common biases:

**Post-COVID Bias:**
- Digital payment adoption is higher than expected
- Work-from-home preferences shifted
- Fix: Update baseline to post-2020 norms

**Common Sense Bias:**
- "Insurance is important" (reality: people don't prioritize it)
- "People save for retirement" (reality: many don't)
- Fix: Use data, not intuition

**Aspiration-Action Gap:**
- "Healthy eating" aspiration (70%) â‰  action (40%)
- Fix: Add action-gap modifier (-30pp for aspirational questions)

---

## Step 4: Test Fixes Systematically (Day 3-5)

### 4.1 Single-Question Testing
**For each proposed fix:**

1. **Backup current prompt:**
   ```
   copy general_system_prompt.txt general_system_prompt_backup.txt
   ```

2. **Apply fix to ONE question only**

3. **Run predictions on full test set**

4. **Measure impact:**
   - Target question error: Before vs After
   - Other questions: Check for regressions
   - Overall accuracy: Should improve or stay flat

5. **Decision:**
   - âœ… **Keep fix if:** Target improves, others stay flat or improve slightly
   - âŒ **Rollback if:** Other questions regress significantly
   - âš ï¸ **Iterate if:** Small improvement, but not enough

### 4.2 Trade-off Analysis Template

| Metric | Before Fix | After Fix | Change |
|--------|------------|-----------|--------|
| **Target Question Error** | 11.5pp | 5.5pp | âœ… -6.0pp |
| **Top Performers (Avg)** | 93.7% | 91.5% | âš ï¸ -2.2pp |
| **Bottom Performers (Avg)** | 67.1% | 73.5% | âœ… +6.4pp |
| **Overall Accuracy** | 84.0% | 87.0% | âœ… +3.0pp |

**Decision Rule:**
- If **overall improves** AND **bottom improves more than top declines** â†’ âœ… Keep fix
- If **top declines more than bottom improves** â†’ âŒ Rollback
- If **overall declines** â†’ âŒ Rollback

---

## Step 5: Calculate Diminishing Returns (Day 5-6)

After fixing the top 2-3 problem questions, evaluate whether to continue:

### 5.1 Effort vs Gain Matrix

| Fix Phase | Questions Fixed | Effort (Days) | Accuracy Gain | ROI |
|-----------|-----------------|---------------|---------------|-----|
| Phase 1 | Cash, Insurance | 3 days | +3.0pp | ðŸŸ¢ HIGH (1pp/day) |
| Phase 2 | Retirement, Switching | 8 days | +1.5pp | ðŸŸ¡ MEDIUM (0.2pp/day) |
| Phase 3 | Healthy eating, etc | 15 days | +0.8pp | ðŸ”´ LOW (0.05pp/day) |

### 5.2 Decision Criteria

**Continue fixing if:**
- âœ… ROI â‰¥ 0.5pp per day
- âœ… Overall accuracy < 85%
- âœ… Multiple demographics still failing (<70%)

**Stop fixing if:**
- âŒ ROI < 0.5pp per day
- âŒ Overall accuracy â‰¥ 87%
- âŒ Only 1-2 edge cases remain
- âŒ Fixes require complex demographic-specific rules (overfitting risk)

---

## Step 6: Document and Deploy (Day 7)

### 6.1 Create Performance Report
```
Final Performance:
- Overall accuracy: 87%
- Pass rate: 95% (21/22 demographics)
- Problem questions remaining: 3 (low priority)

Fixes Applied:
1. Cash preference baseline: 55% â†’ 35% (-20pp, -6.0pp error)
2. Insurance importance baseline: 25% â†’ 12% (-13pp, -5.0pp error)

Fixes Deferred (Diminishing Returns):
1. Provider switching: 6.0pp error, 15 days to fix â†’ ROI too low
2. Healthy eating: 5.8pp error, aspirational gap hard to model
```

### 6.2 Deployment Checklist
- [ ] Backup all prompts with version tags
- [ ] Run final validation on held-out test set
- [ ] Document known limitations (which questions have higher error)
- [ ] Set up monitoring for production (track error drift)
- [ ] Define trigger for retraining (if error increases by >2pp)

---

## Adaptation for Different Dataset Sizes

### Small Datasets (5-6 Demographics, <20 Questions)

**Key Differences:**
- Smaller sample size â†’ Less reliable error patterns
- Fewer questions â†’ Each question has higher impact on overall accuracy

**Modified Process:**
- **Step 2:** Lower threshold for "problem question" to MAE â‰¥ 10pp (instead of 8pp)
- **Step 4:** Test fixes more carefully (smaller dataset = higher overfitting risk)
- **Step 5:** Lower ROI threshold to 0.3pp/day (fewer questions to fix)

**Expected Accuracy:** 75-85% (smaller datasets have higher natural variance)

### Large Datasets (20+ Demographics, 100+ Questions)

**Key Differences:**
- More questions â†’ More opportunities for error
- More demographics â†’ More complex interactions

**Modified Process:**
- **Step 2:** Tighten threshold to MAE â‰¥ 6pp (more questions, so focus on biggest issues)
- **Step 3:** Use clustering to find question groups with similar error patterns
- **Step 4:** Batch-test fixes for related questions (e.g., all financial questions)
- **Step 5:** Higher ROI threshold to 0.7pp/day (more questions available to fix)

**Expected Accuracy:** 85-92% (more data = better patterns)

### Different Question Formats

**Binary (Yes/No) Questions:**
- Error measured in percentage points (0-100pp range)
- Threshold: MAE â‰¥ 10pp is a problem

**Multiple Choice (3+ Options):**
- Error measured by option match rate
- Threshold: <70% correct option is a problem

**Numeric/Continuous:**
- Error measured in absolute units (e.g., predicted income $50K, actual $60K)
- Threshold depends on scale (Â±10% of range is acceptable)

---

## Quick Reference: The 80/20 Rule

### 80% of Accuracy Gains Come From:
1. **Universal baseline fixes** (2-3 days each)
   - Questions where system consistently over/under-predicts for ALL demographics

2. **Post-COVID bias corrections** (1 day each)
   - Digital adoption, work preferences, online shopping

3. **Common sense vs reality gaps** (1 day each)
   - Aspiration vs action, "should" vs "do"

### 20% of Remaining Gains Require:
1. **Demographic-specific rules** (5+ days each)
   - Complex age Ã— income Ã— behavior interactions

2. **Question-type specific modeling** (7+ days each)
   - Aspiration-action gap varies by demographic

3. **Edge case handling** (10+ days total)
   - Questions that work for 90% but fail for 10%

---

## Success Criteria by Dataset Size

| Dataset Size | Target Accuracy | Target Pass Rate | Max Fix Cycles |
|--------------|-----------------|------------------|----------------|
| **Small (5-10 demos)** | 75-80% | 70% | 2 cycles (6 days) |
| **Medium (10-20 demos)** | 80-85% | 80% | 3 cycles (9 days) |
| **Large (20+ demos)** | 85-90% | 85% | 4 cycles (12 days) |

**When to Stop:**
- You've reached target accuracy for your dataset size
- ROI drops below 0.5pp per day
- Only edge cases remain (<5% of demographics affected)

---

## Final Checklist: Before Moving to Next Dataset

- [ ] Documented all problem questions and root causes
- [ ] Applied high-ROI fixes (Phase 1)
- [ ] Deferred low-ROI fixes (Phase 2+) with justification
- [ ] Validated no regressions on top performers
- [ ] Created performance report with known limitations
- [ ] Set up monitoring for production error drift
- [ ] Achieved target accuracy for dataset size

**Time Budget:** 7-12 days from baseline to production-ready system (depending on dataset size)

---

**Key Takeaway:**
Focus on universal baseline fixes first (high ROI), stop when diminishing returns kick in (ROI < 0.5pp/day). 87% accuracy is "good enough" for most business use cases - don't over-engineer for the last 3%.
